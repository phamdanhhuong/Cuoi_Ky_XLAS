import streamlit as st
import cv2
import mediapipe as mp
import joblib
import numpy as np


def show():
    # Load mÃ´ hÃ¬nh
    model = joblib.load('./model/hand_gesture_model.pkl')
    labels = model.classes_

    # Khá»Ÿi táº¡o MediaPipe
    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    hands = mp_hands.Hands(static_image_mode=False,
                        max_num_hands=1,
                        min_detection_confidence=0.5,
                        min_tracking_confidence=0.5)

    st.markdown("<div style='text-align: center; font-size: 24px; font-weight: 600;'>ðŸ¤š Nháº­n diá»‡n cá»­ chá»‰ tay báº±ng MediaPipe + ML</div>", unsafe_allow_html=True)
    st.write("Sá»­ dá»¥ng webcam Ä‘á»ƒ nháº­n diá»‡n cá»­ chá»‰ tay theo thá»i gian thá»±c.")

    run = st.checkbox('Báº¯t Ä‘áº§u nháº­n diá»‡n')
    frame_window = st.image([])

    cap = cv2.VideoCapture(0)

    while run:
        ret, frame = cap.read()
        if not ret:
            st.warning("KhÃ´ng láº¥y Ä‘Æ°á»£c hÃ¬nh tá»« webcam!")
            break

        frame = cv2.flip(frame, 1)
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(rgb)

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                # TrÃ­ch xuáº¥t (x, y, z)
                landmark = []
                for lm in hand_landmarks.landmark:
                    landmark.extend([lm.x, lm.y, lm.z])

                # if len(landmark) == 63:
                #     prediction = model.predict([landmark])[0]
                #     cv2.putText(frame, f'Gesture: {prediction}', (10, 50),
                #                 cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                if len(landmark) == 63:
                    probs = model.predict_proba([landmark])[0]
                    max_prob = np.max(probs)
                    predicted_label = model.classes_[np.argmax(probs)]

                    if max_prob > 0.7:
                        cv2.putText(frame, f'Gesture: {predicted_label} ({max_prob:.2f})', (10, 50),
                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        # Hiá»ƒn thá»‹ lÃªn Streamlit
        frame_window.image(frame, channels="BGR")

    cap.release()